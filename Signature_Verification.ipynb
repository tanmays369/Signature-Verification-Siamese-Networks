{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signature Verification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSxkDAKf0vvE"
      },
      "source": [
        "import os\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.optim import Adam\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "import torchvision.transforms.functional as TrF\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK92_PDsbtzN"
      },
      "source": [
        "batch_size= 16\r\n",
        "num_epochs= 10\r\n",
        "lr= 1e-3\r\n",
        "margin= 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im55YU83dNY2"
      },
      "source": [
        "class SignatureDataset(Dataset):\r\n",
        "    def __init__(self, root_dir, target_file):\r\n",
        "        self.root_dir= root_dir\r\n",
        "        self.target_file= target_file\r\n",
        "    def __getitem__(self, ix):\r\n",
        "        img0= os.path.join(self.root_dir, self.target_file.iloc[ix, 0])\r\n",
        "        img1= os.path.join(self.root_dir, self.target_file.iloc[ix, 1])\r\n",
        "        target= self.target_file.iloc[ix, 2]\r\n",
        "        img0, img1= Image.open(img0), Image.open(img1)\r\n",
        "        img0, img1= self._transform(img0, img1)\r\n",
        "        return img0, img1, target\r\n",
        "    def __len__(self):\r\n",
        "        return len()\r\n",
        "    def _transform(self, img):\r\n",
        "        mean, stdev= [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\r\n",
        "        img0, img1= TrF.resize(img, (75, 100), TrF.resize(img, (75, 100))\r\n",
        "        img0, img1= TrF.to_tensor(img0), TrF.to_tensor(img1)\r\n",
        "        img0, img1= TrF.normalize(img0, mean, stdev), TrF.to_tensor(img1, mean, stdev)\r\n",
        "        return img0, img1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mc2fFQEbaV8"
      },
      "source": [
        "dset= SignatureDataset(\"data/\", \"train.csv\")\r\n",
        "trainloader= DataLoader(dset, batch_size, num_workers= 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5jpYEAvnkFE"
      },
      "source": [
        "class ConvBlock(nn.Module):\r\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding,\r\n",
        "                 use_act= False, use_norm= False, use_pool= False, dropout= False):\r\n",
        "        super(ConvBlock, self).__init__()\r\n",
        "        self.use_act= use_act\r\n",
        "        self.use_norm= use_norm \r\n",
        "        self.use_pool= use_pool \r\n",
        "        self.dropout= dropout\r\n",
        "\r\n",
        "        self.conv= nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\r\n",
        "    def forward(self, x):\r\n",
        "        x= self.conv(x)\r\n",
        "        if self.use_act:\r\n",
        "            x= F.relu(x)\r\n",
        "        if self.use_norm:\r\n",
        "            x= F.local_response_norm(x, k= 2)\r\n",
        "        if self.use_pool:\r\n",
        "            x= F.max_pool2d(x, 2, 2)\r\n",
        "        if self.use_dropout:\r\n",
        "            return F.dropout2d(x, 0.3)\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37NWmZPuhqbp"
      },
      "source": [
        "class SignNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        self.net= nn.Sequential(\r\n",
        "            ConvBlock(1, 96, 11, use_act= True, use_norm= True, use_pool= True),\r\n",
        "            ConvBlock(96, 256, 5, 1, 2, use_norm= True, use_pool= True, dropout= True),\r\n",
        "            ConvBlock(256, 384, 3, 1, 1),\r\n",
        "            ConvBlock(384, 256, 3, 1, 1, use_pool= True, dropout= True),\r\n",
        "            nn.Flatten(1, -1)\r\n",
        "        )\r\n",
        "        self.fc1= (18*26*256, 1024)\r\n",
        "        self.fc2= (1024, 256)\r\n",
        "    def forward(self, x1, x2):\r\n",
        "        x1, x2= self.net(x1), self.net(x2)\r\n",
        "        x1, x2= self.fc1(x1), self.fc2(x2)\r\n",
        "        x1, x2= F.dropout2d(x1), F.dropout2d(x2)\r\n",
        "        return self.fc2(x1), self.fc2(x)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK38FkyjOsHe"
      },
      "source": [
        "class ContrastiveLoss(nn.Module):\r\n",
        "    def __init__(self, margin):\r\n",
        "        super(ContrastiveLoss, self).__init__()\r\n",
        "        self.margin = margin \r\n",
        "\r\n",
        "    def forward(self, p1, p2, target):\r\n",
        "        d= F.pairwise_distance(op1, op2)\r\n",
        "        t1= torch.pow(d, 2)\r\n",
        "        t2= torch.pow(torch.clamp(self.margin - d, min=0.0), 2)\r\n",
        "        loss= torch.mean((1-target)*t1+ (target)*t2)\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVYUWFkcPeR"
      },
      "source": [
        "model= SignNet().cuda()\r\n",
        "loss_fn= ContrastiveLoss(margin)\r\n",
        "optimizer= Adam(model.parameters(), lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JS5suqoZyIv"
      },
      "source": [
        "model.train()\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    running_loss= 0\r\n",
        "    for _, (img1, img2, target) in enumerate(trainloader):\r\n",
        "        img1, img2= img1.float().cuda(), img2.float().cuda() \r\n",
        "        target= target.double.cuda()\r\n",
        "        optimizer.zero_grad()\r\n",
        "        p1, p2= model(img1, img2)\r\n",
        "        loss= loss_fn(p1, p2, target)\r\n",
        "        running_loss+= loss.item()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "    print(f\"Epoch: {epoch+1}; Loss: {running_loss/len(trainloader)}\")\r\n",
        "\r\n",
        "torch.save(model.state_dict(), f\"signature_verification.pth\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}